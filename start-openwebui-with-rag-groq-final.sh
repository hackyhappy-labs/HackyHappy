#!/bin/bash
# =============================================================================
# í”„ë¡œì íŠ¸ëª…: OpenWebUI RAG ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
# ì œì‘ì: <webmaster@vulva.sex>
# ì œì‘ì¼: 2026-01-26
# ì„¤ëª…: Docker + Ollama + Groq + Qdrant ê¸°ë°˜ ì„¤ì¹˜/ìë™í™” ìŠ¤í¬ë¦½íŠ¸
# ë¼ì´ì„¼ìŠ¤: MIT License
# =============================================================================

############################################
# 0. ì‹œìŠ¤í…œ ì‚¬ì–‘ ìë™ ê°ì§€
############################################
echo "ğŸ” ì‹œìŠ¤í…œ ì‚¬ì–‘ ê°ì§€ ì¤‘..."

CPU_CORES=$(nproc 2>/dev/null || echo 1)

TOTAL_RAM_MB=$(free -m | awk '/^Mem:/{print $2}')
AVAILABLE_RAM_MB=$(free -m | awk '/^Mem:/{print $7}')

# ê°’ì´ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ë¹„
TOTAL_RAM_MB=${TOTAL_RAM_MB:-0}
AVAILABLE_RAM_MB=${AVAILABLE_RAM_MB:-0}

TOTAL_RAM=$((TOTAL_RAM_MB / 1024))
AVAILABLE_RAM=$((AVAILABLE_RAM_MB / 1024))

echo "   CPU ì½”ì–´: ${CPU_CORES}ê°œ"
echo "   ì´ ë©”ëª¨ë¦¬: ${TOTAL_RAM}GB"
echo "   ì‚¬ìš© ê°€ëŠ¥: ${AVAILABLE_RAM}GB"

# ì„±ëŠ¥ ë“±ê¸‰ íŒë‹¨
if [ $CPU_CORES -ge 6 ] && [ $TOTAL_RAM -ge 16 ]; then
  PERFORMANCE="HIGH"
  PERF_NAME="ê³ ì„±ëŠ¥ ğŸš€"
  QDRANT_RETRIES=20
  QDRANT_INTERVAL=2
  TOOLS_RETRIES=20
  TOOLS_INTERVAL=2
  WEBUI_RETRIES=30
  WEBUI_INTERVAL=2
  MEMORY_QDRANT="1G"
  MEMORY_TOOLS="2G"
  MEMORY_WEBUI="4G"
elif [ $CPU_CORES -ge 4 ] && [ $TOTAL_RAM -ge 8 ]; then
  PERFORMANCE="MEDIUM_HIGH"
  PERF_NAME="ì¤‘ìƒê¸‰ ğŸ’ª"
  QDRANT_RETRIES=30
  QDRANT_INTERVAL=3
  TOOLS_RETRIES=30
  TOOLS_INTERVAL=3
  WEBUI_RETRIES=40
  WEBUI_INTERVAL=3
  MEMORY_QDRANT="768M"
  MEMORY_TOOLS="1.5G"
  MEMORY_WEBUI="3G"
elif [ $CPU_CORES -ge 2 ] && [ $TOTAL_RAM -ge 4 ]; then
  PERFORMANCE="MEDIUM"
  PERF_NAME="ì¤‘ê¸‰ ğŸ“Š"
  QDRANT_RETRIES=40
  QDRANT_INTERVAL=4
  TOOLS_RETRIES=40
  TOOLS_INTERVAL=4
  WEBUI_RETRIES=60
  WEBUI_INTERVAL=4
  MEMORY_QDRANT="512M"
  MEMORY_TOOLS="1G"
  MEMORY_WEBUI="2G"
else
  PERFORMANCE="LOW"
  PERF_NAME="ì €ì‚¬ì–‘ ğŸ¢"
  QDRANT_RETRIES=60
  QDRANT_INTERVAL=5
  TOOLS_RETRIES=60
  TOOLS_INTERVAL=5
  WEBUI_RETRIES=120
  WEBUI_INTERVAL=5
  MEMORY_QDRANT="384M"
  MEMORY_TOOLS="768M"
  MEMORY_WEBUI="1.5G"
fi

echo ""
echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "ğŸ“Š ê°ì§€ëœ ì„±ëŠ¥: ${PERF_NAME}"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
echo "   ì˜ˆìƒ ì„¤ì¹˜ ì‹œê°„: $(( (QDRANT_RETRIES * QDRANT_INTERVAL + TOOLS_RETRIES * TOOLS_INTERVAL + WEBUI_RETRIES * WEBUI_INTERVAL) / 60 ))ë¶„ ì´ë‚´"
echo "   ë©”ëª¨ë¦¬ í• ë‹¹: Qdrant(${MEMORY_QDRANT}), Tools(${MEMORY_TOOLS}), WebUI(${MEMORY_WEBUI})"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
echo ""

############################################
# 1. root ì‹¤í–‰ ë°©ì§€
############################################
if [ "$EUID" -eq 0 ]; then
  echo "âŒ rootë¡œ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”. ì¼ë°˜ ì‚¬ìš©ìë¡œ ì‹¤í–‰í•˜ì„¸ìš”."
  exit 1
fi

############################################
# 2. Docker ìë™ ì„¤ì¹˜
############################################
if ! command -v docker >/dev/null; then
  echo "âš™ï¸ Docker ë¯¸ì„¤ì¹˜ â†’ ìë™ ì„¤ì¹˜"
  curl -fsSL https://get.docker.com | sh
  sudo usermod -aG docker $USER
  echo "âš ï¸ ë¡œê·¸ì•„ì›ƒ í›„ ì¬ì ‘ì† ë˜ëŠ” newgrp docker í•„ìš”"
  echo "âŒ Docker ì„¤ì¹˜ ì™„ë£Œ. ë‹¤ì‹œ ë¡œê·¸ì¸í•œ í›„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¬ì‹¤í–‰í•˜ì„¸ìš”."
  exit 0
fi

# Docker ì„œë¹„ìŠ¤ í™•ì¸
if ! sudo systemctl is-active --quiet docker; then
  echo "âš™ï¸ Docker ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
  sudo systemctl enable --now docker
  sleep 3
fi

# Docker ê¶Œí•œ í™•ì¸
if ! docker ps >/dev/null 2>&1; then
  echo "âŒ Docker ê¶Œí•œ ì—†ìŒ. ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰ í›„ ì¬ì ‘ì†:"
  echo "   sudo usermod -aG docker $USER"
  echo "   newgrp docker"
  exit 1
fi

############################################
# 3. Ollama ìë™ ê°ì§€ ë° ì„¤ì¹˜
############################################
echo ""
echo "ğŸ” Ollama ì„¤ì¹˜ ìƒíƒœ í™•ì¸ ì¤‘..."

OLLAMA_INSTALLED=false
OLLAMA_RUNNING=false

# Ollama ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸
if command -v ollama >/dev/null 2>&1; then
  OLLAMA_INSTALLED=true
  echo "   âœ… Ollama ì´ë¯¸ ì„¤ì¹˜ë¨"
  
  # Ollama ì„œë²„ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
  if pgrep -x "ollama" >/dev/null; then
    OLLAMA_RUNNING=true
    echo "   âœ… Ollama ì„œë²„ ì‹¤í–‰ ì¤‘"
  else
    echo "   âš ï¸ Ollama ì„œë²„ ì¤‘ì§€ ìƒíƒœ"
  fi
else
  echo "   â„¹ï¸ Ollama ë¯¸ì„¤ì¹˜"
fi

# Ollama ì„¤ì¹˜/ì‚¬ìš© ì—¬ë¶€ ê²°ì •
if [ "$OLLAMA_INSTALLED" = true ]; then
  # ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš° - ì‚¬ìš© ì—¬ë¶€ë§Œ ë¬»ê¸°
  echo ""
  echo "ğŸ’¡ Ollamaê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
  read -p "ğŸ¤– Ollamaë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): " USE_OLLAMA_INPUT
  USE_OLLAMA_INPUT=${USE_OLLAMA_INPUT:-Y}
  
  if [[ "$USE_OLLAMA_INPUT" =~ ^[Yy]$ ]]; then
    USE_OLLAMA=true
    
    # ì„œë²„ê°€ ì¤‘ì§€ë˜ì–´ ìˆìœ¼ë©´ ì‹œì‘
    if [ "$OLLAMA_RUNNING" = false ]; then
      echo "âš™ï¸ Ollama ì„œë²„ ì‹œì‘ ì¤‘..."
      nohup ollama serve > /tmp/ollama.log 2>&1 &
      sleep 5
      echo "   âœ… Ollama ì„œë²„ ì‹œì‘ ì™„ë£Œ"
    fi
    
    # Systemd ì„œë¹„ìŠ¤ ë“±ë¡ (ì¬ë¶€íŒ… ì‹œ ìë™ ì‹œì‘)
    echo "âš™ï¸ Ollama ìë™ ì‹œì‘ ì„¤ì • ì¤‘..."
    if sudo systemctl is-enabled ollama >/dev/null 2>&1; then
      echo "   âœ… Ollama ìë™ ì‹œì‘ ì´ë¯¸ í™œì„±í™”ë¨"
    else
      if sudo systemctl enable ollama 2>/dev/null; then
        echo "   âœ… Ollama ìë™ ì‹œì‘ í™œì„±í™”"
      else
        echo "   âš ï¸ Ollama ìë™ ì‹œì‘ ì„¤ì • ì‹¤íŒ¨ (ìˆ˜ë™ ê´€ë¦¬ í•„ìš”)"
      fi
    fi
    
    # í•„ìš”í•œ ëª¨ë¸ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
    echo "ğŸ“‹ ì„ë² ë”© ëª¨ë¸ í™•ì¸ ì¤‘..."
    if ! ollama list | grep -q "nomic-embed-text"; then
      echo "ğŸ“¥ nomic-embed-text ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."
      ollama pull nomic-embed-text || echo "âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ë‚˜ì¤‘ì— ì¬ì‹œë„ ê°€ëŠ¥)"
    else
      echo "   âœ… nomic-embed-text ëª¨ë¸ ì´ë¯¸ ì¡´ì¬"
    fi
  else
    USE_OLLAMA=false
    echo "â­ï¸ Ollama ì‚¬ìš© ì•ˆ í•¨"
  fi
  
else
  # ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° - ì„±ëŠ¥ë³„ ê¶Œì¥ì‚¬í•­ ì œì‹œ
  echo ""
  if [ "$PERFORMANCE" = "HIGH" ] || [ "$PERFORMANCE" = "MEDIUM_HIGH" ]; then
    echo "ğŸ’¡ ${PERF_NAME} ì‹œìŠ¤í…œ â†’ Ollama ì„¤ì¹˜ ê¶Œì¥ (ë¡œì»¬ ì„ë² ë”©)"
    read -p "ğŸ¤– Ollamaë¥¼ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): " INSTALL_OLLAMA
    INSTALL_OLLAMA=${INSTALL_OLLAMA:-Y}
  else
    echo "ğŸ’¡ ${PERF_NAME} ì‹œìŠ¤í…œ â†’ Groq API ì‚¬ìš© ê¶Œì¥ (ë¦¬ì†ŒìŠ¤ ì ˆì•½)"
    read -p "ğŸ¤– Ollamaë¥¼ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " INSTALL_OLLAMA
    INSTALL_OLLAMA=${INSTALL_OLLAMA:-N}
  fi
  
  if [[ "$INSTALL_OLLAMA" =~ ^[Yy]$ ]]; then
    echo "âš™ï¸ Ollama ì„¤ì¹˜ ì¤‘..."
    curl -fsSL https://ollama.com/install.sh | sh
    
    echo "âš™ï¸ Ollama ìë™ ì‹œì‘ ì„¤ì • ì¤‘..."
    if sudo systemctl enable ollama 2>/dev/null && sudo systemctl start ollama 2>/dev/null; then
      sleep 5
      echo "   âœ… Ollama ì„œë¹„ìŠ¤ í™œì„±í™” ì™„ë£Œ"
    else
      echo "   âš ï¸ Ollama ì„œë¹„ìŠ¤ ë“±ë¡ ì‹¤íŒ¨, ìˆ˜ë™ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤..."
      nohup ollama serve > /tmp/ollama.log 2>&1 &
      sleep 5
    fi
    
    echo "ğŸ“¥ nomic-embed-text ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."
    ollama pull nomic-embed-text || echo "âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ë‚˜ì¤‘ì— ì¬ì‹œë„ ê°€ëŠ¥)"
    
    USE_OLLAMA=true
    echo "   âœ… Ollama ì„¤ì¹˜ ë° ì„¤ì • ì™„ë£Œ"
  else
    USE_OLLAMA=false
    echo "â­ï¸ Ollama ì„¤ì¹˜ ê±´ë„ˆëœ€"
  fi
fi

############################################
# 4. GPU ê°ì§€
############################################
if command -v nvidia-smi >/dev/null 2>&1; then
  OPEN_WEBUI_IMAGE="ghcr.io/open-webui/open-webui:cuda"
  echo "âœ… NVIDIA GPU ê°ì§€ (CUDA)"
else
  OPEN_WEBUI_IMAGE="ghcr.io/open-webui/open-webui:main"
  echo "â„¹ï¸ GPU ì—†ìŒ (CPU ëª¨ë“œ)"
fi

############################################
# 5. Groq API Key (ì„ íƒ ì…ë ¥, ì €ì¥ ê°€ëŠ¥)
############################################
echo ""
echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "ğŸ”‘ Groq API Key ì„¤ì • (ì„ íƒì‚¬í•­)"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"

if [ "$USE_OLLAMA" = false ]; then
  echo "âš ï¸  Ollamaë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Groq API í‚¤ ê¶Œì¥"
  echo "   (ì—†ìœ¼ë©´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤)"
  echo ""
fi

read -t 60 -p "ğŸ”‘ Groq API Key ì…ë ¥ (60ì´ˆ ë‚´ Enter=ê±´ë„ˆëœ€): " GROQ_API_KEY || true
GROQ_API_KEY=$(echo "$GROQ_API_KEY" | xargs)  # ê³µë°± ì œê±°

if [ -n "$GROQ_API_KEY" ]; then
  echo "âœ… Groq API Key ì €ì¥ë¨"
  USE_GROQ=true
else
  echo "â­ï¸ Groq API Key ê±´ë„ˆëœ€"
  USE_GROQ=false
  
  # Ollamaë„ ì—†ê³  Groqë„ ì—†ìœ¼ë©´ ê²½ê³ 
  if [ "$USE_OLLAMA" = false ]; then
    echo ""
    echo "âš ï¸  ê²½ê³ : Ollamaì™€ Groq ëª¨ë‘ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤."
    echo "   ì„¤ì¹˜ í›„ Settingsì—ì„œ API í‚¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜"
    echo "   Ollamaë¥¼ ì„¤ì¹˜í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    echo ""
    read -t 30 -p "   ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (30ì´ˆ í›„ ìë™ ì§„í–‰) [Y/n]: " CONTINUE || CONTINUE="Y"
    CONTINUE=${CONTINUE:-Y}
    if [[ ! "$CONTINUE" =~ ^[Yy]$ ]] && [ "$CONTINUE" != "" ]; then
      echo "âŒ ì„¤ì¹˜ ì¤‘ë‹¨ë¨"
      exit 0
    fi
  fi
fi

############################################
# 6. ì‘ì—… ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
############################################
BASE_DIR="$HOME/openapi-rag"
if [ -d "$BASE_DIR" ]; then
  echo "ğŸ§¹ ê¸°ì¡´ ì„¤ì¹˜ ì œê±° ì¤‘..."
  cd "$BASE_DIR"
  docker compose down -v 2>/dev/null || true
  cd ~
  rm -rf "$BASE_DIR"
fi

mkdir -p "$BASE_DIR/tools-api/data"
cd "$BASE_DIR"

############################################
# 7. .env
############################################
cat > .env <<EOF
# Qdrant ì„¤ì •
VECTOR_DB=qdrant
QDRANT_URI=http://qdrant:6333
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=openapi_rag
EOF

if [ "$USE_OLLAMA" = true ]; then
cat >> .env <<EOF

# Ollama ì„¤ì • (ì„ë² ë”©ìš©)
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
EOF
fi

if [ "$USE_GROQ" = true ] && [ -n "$GROQ_API_KEY" ]; then
cat >> .env <<EOF

# Groq API ì„¤ì •
OPENAI_API_KEY=$GROQ_API_KEY
OPENAI_API_BASE_URL=https://api.groq.com/openai/v1
EOF
fi

chmod 600 .env

############################################
# 8. OpenAPI Tool Server
############################################
cat > tools-api/requirements.txt <<EOF
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.3
requests==2.31.0
python-multipart==0.0.6
pypdf==3.17.4
qdrant-client==1.7.0
numpy==1.26.3
ollama==0.1.6
EOF

# ì„±ëŠ¥ë³„ ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •
PYTHON_RETRIES=$((QDRANT_RETRIES / 2))

cat > tools-api/main.py <<EOF
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os, uuid, time
from pypdf import PdfReader
import ollama
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct

app = FastAPI(
    title="OpenAPI RAG Tool Server",
    description="Standard OpenAPI-based Retrieval-Augmented Generation Tool Server (Qdrant + Ollama)",
    version="1.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
QDRANT_URL = os.getenv("QDRANT_URL", "http://qdrant:6333")
COLLECTION = os.getenv("QDRANT_COLLECTION", "openapi_rag")
MODEL = os.getenv("OLLAMA_EMBED_MODEL", "nomic-embed-text")
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://host.docker.internal:11434")
DATA_DIR = "/app/data"

# Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì„±ëŠ¥ë³„ ì¬ì‹œë„)
client = None
RETRIES = ${PYTHON_RETRIES}
INTERVAL = ${QDRANT_INTERVAL}

print(f"ğŸ”„ Qdrant ì—°ê²° ì‹œë„ ì¤‘... (ìµœëŒ€ {RETRIES}íšŒ, {INTERVAL}ì´ˆ ê°„ê²©)")
for attempt in range(RETRIES):
    try:
        client = QdrantClient(url=QDRANT_URL)
        client.get_collections()
        print(f"âœ… Qdrant ì—°ê²° ì„±ê³µ: {QDRANT_URL}")
        break
    except Exception as e:
        print(f"â³ Qdrant ì—°ê²° ëŒ€ê¸° ì¤‘... ({attempt+1}/{RETRIES})")
        time.sleep(INTERVAL)

if not client:
    print("âŒ Qdrant ì—°ê²° ì‹¤íŒ¨")

# ì»¬ë ‰ì…˜ ìƒì„±
if client:
    try:
        collections = [c.name for c in client.get_collections().collections]
        if COLLECTION not in collections:
            client.create_collection(
                collection_name=COLLECTION,
                vectors_config=VectorParams(size=768, distance=Distance.COSINE),
            )
            print(f"âœ… ì»¬ë ‰ì…˜ ìƒì„±: {COLLECTION}")
        else:
            print(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚¬ìš©: {COLLECTION}")
    except Exception as e:
        print(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")

def embed(text: str):
    try:
        ollama_client = ollama.Client(host=OLLAMA_BASE_URL)
        response = ollama_client.embeddings(model=MODEL, prompt=text)
        return response["embedding"]
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Embedding error: {str(e)}")

@app.post("/documents/upload", summary="Upload document for RAG indexing")
async def upload_pdf(file: UploadFile = File(...)):
    if not client:
        raise HTTPException(status_code=503, detail="Qdrant client not initialized")
    
    try:
        path = f"{DATA_DIR}/{file.filename}"
        with open(path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        print(f"ğŸ“„ íŒŒì¼ ì €ì¥: {file.filename}")

        reader = PdfReader(path)
        text = "".join(p.extract_text() or "" for p in reader.pages)
        
        if not text.strip():
            raise HTTPException(status_code=400, detail="PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
        
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ: {len(text)} ë¬¸ì")

        chunks = []
        chunk_size = 1000
        overlap = 100
        for i in range(0, len(text), chunk_size - overlap):
            chunk = text[i:i + chunk_size].strip()
            if chunk:
                chunks.append(chunk)
        
        print(f"âœ‚ï¸ ì²­í¬ ë¶„í• : {len(chunks)}ê°œ")

        points = []
        for idx, chunk in enumerate(chunks):
            try:
                vector = embed(chunk)
                points.append(
                    PointStruct(
                        id=str(uuid.uuid4()),
                        vector=vector,
                        payload={"text": chunk, "source": file.filename, "chunk_index": idx},
                    )
                )
                if (idx + 1) % 10 == 0:
                    print(f"ğŸ”¢ ì„ë² ë”©: {idx + 1}/{len(chunks)}")
            except Exception as e:
                print(f"âš ï¸ ì²­í¬ {idx} ì‹¤íŒ¨: {e}")
                continue

        if not points:
            raise HTTPException(status_code=500, detail="ì„ë² ë”© ì‹¤íŒ¨")

        client.upsert(collection_name=COLLECTION, points=points)
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {len(points)}ê°œ")
        
        return {
            "status": "success",
            "filename": file.filename,
            "total_chunks": len(chunks),
            "indexed_chunks": len(points),
            "collection": COLLECTION
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Upload error: {str(e)}")

class SearchQuery(BaseModel):
    query: str
    top_k: int = 3

@app.post("/rag/search", summary="Semantic search for RAG")
def rag_search(search: SearchQuery):
    if not client:
        raise HTTPException(status_code=503, detail="Qdrant client not initialized")
    
    try:
        query_vector = embed(search.query)
        hits = client.search(
            collection_name=COLLECTION,
            query_vector=query_vector,
            limit=search.top_k,
        )
        
        results = [
            {
                "text": h.payload.get("text", ""),
                "source": h.payload.get("source", ""),
                "chunk_index": h.payload.get("chunk_index", 0),
                "score": h.score
            }
            for h in hits
        ]
        
        return {"query": search.query, "results": results, "count": len(results)}
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")

@app.get("/health", summary="Health check")
def health():
    try:
        if not client:
            return {"status": "unhealthy", "error": "Qdrant client not initialized"}
        client.get_collections()
        return {"status": "healthy", "qdrant_url": QDRANT_URL, "collection": COLLECTION, "embed_model": MODEL}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

@app.get("/", summary="API Info")
def root():
    return {
        "service": "OpenAPI RAG Tool Server",
        "version": "1.0.0",
        "endpoints": {
            "docs": "/docs",
            "openapi": "/openapi.json",
            "upload": "/documents/upload",
            "search": "/rag/search",
            "health": "/health"
        }
    }
EOF

cat > tools-api/Dockerfile <<EOF
FROM python:3.11-slim
WORKDIR /app
RUN apt-get update && apt-get install -y gcc curl && rm -rf /var/lib/apt/lists/*
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY main.py .
RUN mkdir -p /app/data
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
EOF

############################################
# 9. docker-compose.yml (ìˆ˜ì • - Ollama ëª¨ë¸ í‘œì‹œ ì§€ì›)
############################################
SECRET_KEY=$(openssl rand -hex 32)

cat > docker-compose.yml <<EOF
services:
  qdrant:
    image: qdrant/qdrant:latest
    volumes:
      - qdrant-data:/qdrant/storage
    ports:
      - "6333:6333"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${MEMORY_QDRANT}

  openapi-tools:
    build: ./tools-api
    env_file: .env
    volumes:
      - ./tools-api/data:/app/data
    ports:
      - "8000:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - qdrant
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${MEMORY_TOOLS}

  open-webui:
    image: $OPEN_WEBUI_IMAGE
    environment:
      - WEBUI_SECRET_KEY=$SECRET_KEY
      - VECTOR_DB=qdrant
      - QDRANT_URI=http://qdrant:6333
EOF

# Ollama ì„¤ì • ì¶”ê°€ (USE_OLLAMAì— ë”°ë¼)
if [ "$USE_OLLAMA" = true ]; then
cat >> docker-compose.yml <<EOF
      - ENABLE_OLLAMA_API=true
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
EOF
else
cat >> docker-compose.yml <<EOF
      - ENABLE_OLLAMA_API=false
EOF
fi

# Groq API ì„¤ì • ì¶”ê°€
if [ "$USE_GROQ" = true ] && [ -n "$GROQ_API_KEY" ]; then
cat >> docker-compose.yml <<EOF
      - ENABLE_OPENAI_API=true
      - OPENAI_API_KEY=$GROQ_API_KEY
      - OPENAI_API_BASE_URL=https://api.groq.com/openai/v1
      - DEFAULT_MODELS=llama-3.3-70b-versatile
EOF
else
cat >> docker-compose.yml <<EOF
      - ENABLE_OPENAI_API=false
EOF
fi

# ë‚˜ë¨¸ì§€ open-webui ì„¤ì •
cat >> docker-compose.yml <<EOF
    volumes:
      - open-webui-data:/app/backend/data
    ports:
      - "0.0.0.0:3000:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - qdrant
      - openapi-tools
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: ${MEMORY_WEBUI}

volumes:
  qdrant-data:
  open-webui-data:
EOF
      
############################################
# 10. ì‹¤í–‰ (ì„±ëŠ¥ë³„ ëŒ€ê¸° ì‹œê°„)
############################################
echo ""
echo "ğŸ”¨ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
docker compose build

echo ""
echo "ğŸš€ ì»¨í…Œì´ë„ˆ ì‹œì‘..."
docker compose up -d

echo ""
echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "â³ ${PERF_NAME} - ì„œë¹„ìŠ¤ ì¤€ë¹„ ëŒ€ê¸°"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"

# Qdrant ëŒ€ê¸°
echo ""
echo "ğŸ“¦ 1/3 Qdrant ì‹œì‘ ì¤‘..."
for i in $(seq 1 $QDRANT_RETRIES); do
  if docker compose exec -T qdrant timeout 3 curl -s http://localhost:6333/collections >/dev/null 2>&1; then
    echo "   âœ… Qdrant ì¤€ë¹„ ì™„ë£Œ! (${i}/${QDRANT_RETRIES})"
    break
  fi
  printf "   â³ ëŒ€ê¸° ì¤‘... %d/%d\r" $i $QDRANT_RETRIES
  sleep $QDRANT_INTERVAL
done

# OpenAPI Tools ëŒ€ê¸°
echo ""
echo "ğŸ§  2/3 OpenAPI Tools ì‹œì‘ ì¤‘..."
for i in $(seq 1 $TOOLS_RETRIES); do
  if timeout 3 curl -s http://localhost:8000/health >/dev/null 2>&1; then
    echo "   âœ… OpenAPI Tools ì¤€ë¹„ ì™„ë£Œ! (${i}/${TOOLS_RETRIES})"
    break
  fi
  printf "   â³ ëŒ€ê¸° ì¤‘... %d/%d\r" $i $TOOLS_RETRIES
  sleep $TOOLS_INTERVAL
done

# Open WebUI ëŒ€ê¸°
echo ""
echo "ğŸŒ 3/3 Open WebUI ì‹œì‘ ì¤‘..."
for i in $(seq 1 $WEBUI_RETRIES); do
  if docker compose logs open-webui 2>&1 | grep -q "Application startup complete\|Uvicorn running"; then
    sleep 3
    if timeout 3 curl -s http://localhost:3000 >/dev/null 2>&1; then
      echo "   âœ… Open WebUI ì¤€ë¹„ ì™„ë£Œ! (${i}/${WEBUI_RETRIES})"
      break
    fi
  fi
  printf "   â³ ëŒ€ê¸° ì¤‘... %d/%d\r" $i $WEBUI_RETRIES
  sleep $WEBUI_INTERVAL
done

echo ""
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"

# ìµœì¢… ìƒíƒœ
echo ""
echo "ğŸ“Š ì»¨í…Œì´ë„ˆ ìƒíƒœ:"
docker compose ps

echo ""
echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "ğŸ‰ ì„¤ì¹˜ ì™„ë£Œ!"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
echo ""
echo "ğŸ“Š ì„¤ì¹˜ëœ êµ¬ì„±:"
if [ "$USE_OLLAMA" = true ]; then
  echo "   âœ… Ollama: í™œì„±í™” (ë¡œì»¬ ëª¨ë¸)"
else
  echo "   â­ï¸ Ollama: ë¹„í™œì„±í™”"
fi
if [ "$USE_GROQ" = true ]; then
  echo "   âœ… Groq API: í™œì„±í™” (í´ë¼ìš°ë“œ ëª¨ë¸)"
else
  echo "   â­ï¸ Groq API: ë¹„í™œì„±í™”"
fi
echo ""
echo "ğŸŒ ì„œë¹„ìŠ¤ URL:"
echo "   Open WebUI        : http://localhost:3000"
echo "   OpenAPI Tool Docs : http://localhost:8000/docs"
echo "   Qdrant Dashboard  : http://localhost:6333/dashboard"
echo ""
echo "ğŸ’¡ ì‚¬ìš© ë°©ë²•:"
echo "   1. http://localhost:3000 ì ‘ì†"
echo "   2. ê³„ì • ìƒì„± (ì²« ê³„ì •ì´ ê´€ë¦¬ì)"

if [ "$USE_OLLAMA" = true ] && [ "$USE_GROQ" = true ]; then
  echo "   3. Settings â†’ Modelsì—ì„œ Ollama + Groq ëª¨ë¸ ëª¨ë‘ í‘œì‹œë¨"
  echo "   4. ì±„íŒ… ì‹œ ì›í•˜ëŠ” ëª¨ë¸ ì„ íƒ ê°€ëŠ¥"
elif [ "$USE_OLLAMA" = true ]; then
  echo "   3. Settings â†’ Modelsì—ì„œ Ollama ë¡œì»¬ ëª¨ë¸ë§Œ í‘œì‹œë¨"
  echo "   4. Groq ëª¨ë¸ ì¶”ê°€: Settings â†’ Connections â†’ OpenAIì—ì„œ API í‚¤ ì…ë ¥"
elif [ "$USE_GROQ" = true ]; then
  echo "   3. Settings â†’ Modelsì—ì„œ Groq í´ë¼ìš°ë“œ ëª¨ë¸ë§Œ í‘œì‹œë¨"
  echo "   4. Ollama ì¶”ê°€: í˜¸ìŠ¤íŠ¸ì—ì„œ 'ollama serve' ì‹¤í–‰ í›„ ì¬ì‹œì‘"
else
  echo "   3. âš ï¸  í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ"
  echo "   4. Settings â†’ Connectionsì—ì„œ API í‚¤ ì¶”ê°€ ë˜ëŠ”"
  echo "      í˜¸ìŠ¤íŠ¸ì—ì„œ Ollama ì„¤ì¹˜ í›„ ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘"
fi

echo ""
echo "ğŸ“š RAG ì‚¬ìš© ë°©ë²•:"
echo ""
echo "   1ï¸âƒ£  PDF ì—…ë¡œë“œ:"
echo "      curl -X POST http://localhost:8000/documents/upload \\"
echo "           -F 'file=@document.pdf'"
echo ""
echo "   2ï¸âƒ£  Open WebUIì—ì„œ ì‚¬ìš©:"
echo "      ì…ë ¥ì°½ì— @rag_search : [ê²€ìƒ‰ì–´]ì— ëŒ€í•´ ì°¾ì•„ì¤˜"
echo ""
echo "   3ï¸âƒ£  RAG ìƒíƒœ í™•ì¸:"
echo "      curl http://localhost:8000/health"
echo ""
echo ""
echo "ğŸ”§ ê´€ë¦¬ ëª…ë ¹ì–´:"
echo "   cd ~/openapi-rag"
echo "   docker compose logs -f          # ì „ì²´ ë¡œê·¸ í™•ì¸"
echo "   docker compose logs -f open-webui   # WebUI ë¡œê·¸ë§Œ"
echo "   docker compose restart          # ì¬ì‹œì‘"
echo "   docker compose down             # ì¤‘ì§€"
echo "   docker compose down -v          # ì¤‘ì§€ + ë°ì´í„° ì‚­ì œ"
echo ""
if [ "$USE_OLLAMA" = true ]; then
echo "ğŸ¤– Ollama ì„œë¹„ìŠ¤ ê´€ë¦¬:"
echo "   systemctl status ollama  # Ollama ìƒíƒœ í™•ì¸"
echo "   systemctl restart ollama # Ollama ì¬ì‹œì‘"
echo "   sudo journalctl -u ollama -f  # Ollama ë¡œê·¸"
echo "   ollama list  # ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸"
echo ""
fi
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
